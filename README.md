
<h3 align="center">
<p> VLStereoSet: A Study of Stereotypical Bias in Pre-trained Vision-Language Models
</h3>


This repository contains VLStereoSet. The dataset to measure stereotypical bias on Visual Language Pretrained Models (VL-PTMs). The detailed data construction process is describled in Data Construction Section of  [VLStereoSet: A Study of Stereotypical Bias in Pre-trained Vision-Language Models]([https://pages.github.com/](https://aclanthology.org/2022.aacl-main.40.pdf))


## Disclaimer

The image url is retrieved from Google Image Search. We does not create this image, vouch for its accuracy, or guarantee that it is the most recent data available from the data provider. Images might be subject to copyright. Please refer to "Find images you can use & share" below provided by Googleï¼š

https://support.google.com/websearch/answer/29508?hl=en&co=GENIE.Platform%3DAndroid

## Citation
To cite VLStereoSet: 

```
@inproceedings{zhou-etal-2022-vlstereoset,
    title = "{VLS}tereo{S}et: A Study of Stereotypical Bias in Pre-trained Vision-Language Models",
    author = "Zhou, Kankan and Lai, Eason and Jiang, Jing",
    booktitle = "Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    year = "2022",


}
```
